{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('python_modules')",
   "metadata": {
    "interpreter": {
     "hash": "9634d4b890a726f71d8044046bc71cdc391c406dc663847f104c7db04bcb4cdc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'pos': [':)', ':))', ':D', ':DD', 'xD', 'xDD', ':d=)', '=))', \":')\", \"=')\", ':}', ':}}', ':]', ':]]', '(:', 'C:', ':P', 'üòÇ', '‚ù§', '‚ô•', 'üòç', 'üòò', 'üòä', 'üëå', 'üíï', 'üëè', 'üòÅ', '‚ò∫', '‚ô°', 'üëç', 'üôè', '‚úå', 'üòè', 'üòâ', 'üôå', 'üôà', 'üí™', 'üòÑ', 'üíÉ', 'üíñ', 'üòÉ', 'üò±', 'üéâ', 'üòú', 'üå∏', 'üíú', 'üíô', 'üò≥', 'üíó', '‚òÄ', 'üòé', 'üò¢', 'üíã', 'üòã', 'üôä', 'üé∂', 'üíû', 'üòå', 'üíØ', 'üíõ', 'üíÅ', 'üíö', 'üòÜ', 'üòù', 'üòÖ', 'üëä', 'üòÄ', 'üòö', 'üòª', 'üíò', 'üëã', '‚úã', 'üéä', 'üçï', '‚ùÑ', 'üò•', 'üòà', 'üîù', '‚öΩ', 'üëë', 'üòπ', 'üçÉ', 'üéÅ', 'üêß', 'üéà', '‚úä', 'üí§', 'üíì', 'üí¶', 'üôã', 'üéÑ', 'üéµ', 'üòõ', 'üò¨', 'üëØ', 'üíé', 'üéÇ', 'üë´', 'üèÜ', '‚òù', 'üòô', '‚õÑ', 'üëÖ', '‚ô™', 'üçÇ', 'üíè', 'üå¥', 'üëà', 'üåπ', 'üôÜ', 'üçª', 'üåû', 'üçÅ', '‚≠ê', 'üéÄ', 'üôâ', 'üå∫', 'üíÖ', 'üê∂', 'üåö', 'üé§', 'üë≠', 'üéß', 'üëÜ', 'üç∏', 'üçâ', 'üòá', 'üèÉ', 'üç∫', 'üé∏', 'üçπ', 'üí´', 'üìö', 'üå∑', 'üíù', 'üí®', 'üèà', 'üíç', '‚òî', 'üë∏', 'üá™', 'üç©', '‚òÅ', 'üåª', 'üòµ', '‚Üø', 'üêØ', 'üëº', 'üçî', 'üò∏', 'üë∂', '‚Üæ', 'üíê', 'üåä', 'üç¶', 'üçì', 'üíÜ', 'üç¥', 'üá∏', 'üòÆ', 'üòΩ', 'üåà', 'üôÄ', 'üéÆ', 'üçÜ', 'üç∞', 'üôá', 'üçü', 'üçå', 'üíë', 'üê£', 'üéÉ', 'üòü', 'üêæ', 'üéì', 'üèä', 'üç´', 'üì∑', 'üëÑ', 'üåº', 'üê±', 'üá∫', 'üö¨', 'üìñ', 'üêí', 'üåç', '‚îä', 'üê•', 'üíÑ', 'üí∏', '‚õî', 'üèÄ', 'üíâ', 'üíü', 'üòØ', '‚ô¶', 'üåô', 'üêü', 'üë£', 'üóø', 'üçù', 'üç≠', '‚ùå', 'üê∞', 'üíä', 'üö®', 'üç™', 'üéÜ', 'üéé', 'üá©', '‚úÖ', 'üçë', 'üîä', 'üåå', 'üçé', 'üêª', 'üíá', 'üçä', 'üçí', 'üê≠', 'üëü', 'üåé', 'üçç', 'üêÆ', 'üì≤', 'üåÖ', 'üá∑', 'üë†', 'üåΩ', 'üç¨', 'üò∫', 'üöÄ', '¬¶', 'üçß', 'üçú', 'üêè', 'üëß', 'üèÑ', 'üçã', 'üÜó', 'üì∫', 'üçÖ', '‚õÖ', 'üëô', 'üè°', 'üåæ', '‚úè', 'üê¨', 'üáπ', '‚ô£', 'üáÆ', 'üêç', '‚ôî', 'üç≥', 'üîµ', 'üåï', 'üê®', 'üîê', 'üíø', 'üå≥', 'üë∞', '‚öì', 'üö¥', 'üëó', '‚ûï', 'üí¨', 'üîú', 'üç®', 'üçô', 'üçó', 'üç≤', 'üòº', 'üêô', 'üë®', 'üçö', 'üçñ', '‚ô®', '‚ñÉ', 'üöò', 'üë©', 'üê†', 'üöπ', 'üíµ', '‚ú∞', 'üëõ', 'üå±', 'üåè', 'üå≤', 'üë¥', 'üè†', 'üçá', 'üçò', 'üçõ', 'üêá', 'üëµ', 'üåµ', 'üéá', 'üêé', 'üê§', 'üõÄ', 'üåë', 'üö≤', 'üèÅ', 'üéæ', 'üêµ', '‚óï', 'üóº', 'üçµ', 'üçØ', '‚á®', 'üåì', 'üîí', 'üë≥', '‚ô©', 'üíå', 'üåú', 'üöø', 'üîÜ', 'üåõ', 'üè©', 'üá´', 'üì¢', 'üê¶', '‚ôª', 'üåò', 'üçê', 'üåî', '‚ï•', 'üëñ', 'üòó', 'üêÑ', '‚¨á', 'üöº', 'üåó', 'üåñ', 'üîÖ', 'üëú', 'üêå', 'üíº', 'üêπ', 'üå†', '‚ö´', '‚ôß', 'üé¢', 'üé∑', 'üåá', '‚è∞', '‚ó†', 'üéø', 'üÜî', 'üåí', 'üê™', '‚ïù', 'üëî', 'üêã', '‚ñΩ', 'üêõ', 'üëï', 'üí≥', 'üèß', 'üí°', '‚¨Ö', 'üá±', 'üìπ', 'üëû', 'üöë', 'üÜò', 'üëö', 'üöç', 'üö£', 'üèâ', 'üóª', '‚õ∫', 'üèÇ', 'üë°', 'üìª', 'üå∞', 'üéí', '‚åí', 'üì¥', 'üö¢', 'üîî', '‚ó¢', 'üè•', 'üÉè', 'üíí', 'üêê', 'üîö', 'üîì', 'üéΩ', 'üìÖ', 'üé∫', '‚úâ', '‚ó§', '‚óã', 'üçº', 'üì£', 'üêó', '‚õ≥', '‚îõ', '‚îÉ', 'üí∫', '‚òª', 'üìû', 'üåâ', '‚úé', 'üìÉ', 'üí∑', 'üöÑ', '‚ñ≤', '‚õµ', '‚åõ', 'üöú', 'üëí', '‚ùï', 'üîõ', 'üá≤', '‚ùÖ', 'üëù', '‚úû', 'üéã', 'üë•', '‚óÜ', 'üî≠', 'üêú', '‚ôå', 'üë∑', 'üìÑ', 'üöê', 'üåã', 'üì°', 'üö≥', '‚úò', 'üÖ∞', 'üáº', '‚îì', '‚î£', '‚ìÅ', '‚í∫', 'üë§', 'üé†', 'üìó', 'üî©', 'üë¢', 'üì∞', '‚ìÇ'], 'neu': [':|', ':/', ':\\\\', '', '‚òØ', '‚ú®', '‚òÖ', '‚ñà', 'üî•', '‚ô´', 'ÔøΩ', '¬©', 'üëÄ', 'üêì', '‚òï', 'üí•', '‚ñ∫', '‚úà', 'üëâ', '‚òÜ', 'üçÄ', 'üéÖ', '‚úî', '‚ö°', '‚û°', 'üåø', 'üåü', 'üîÆ', '‚ùó', '‚úñ', 'üî™', '‚ûú', 'üëª', 'üí∞', '‚ñ™', '‚îÅ', '‚ò∑', 'üê∑', 'üëΩ', 'üç∑', '¬Æ', '‚òë', '‚îÇ', 'üí£', '‚ñ∂', '‚ñë', 'üëæ', 'üìí', 'üëá', '‚ñì', '‚ö†', '‚ïØ', '‚úì', '‚ñ¨', 'üö∂', '‚ïë', 'üê∏', '‚úø', 'üåÄ', 'üêº', 'üé•', '‚óè', 'üöó', 'üìù', '‚ïê', 'üí≠', '‚òû', 'üåÉ', '‚ï≠', '‚úß', '‚ïÆ', 'üëπ', 'üì±', 'üéº', '‚îÄ', '‚ï∞', '‚ô¨', '‚ôö', 'üî¥', '‚òº', '‚ùì', 'üê¥', 'üí¢', 'üé¨', 'üêò', '‚†Ä', '‚û§', '‚¨Ü', '‚ö™', 'üê¢', '‚óâ', 'üç§', 'üêù', 'üåù', '‚ùÅ', '‚ùÄ', '‚ñÄ', '‚ñí', 'üí≤', '‚õΩ', '‚ñ∏', '‚ôõ', 'üéπ', '‚ôï', 'üçè', 'üë¶', 'üá¨', 'üáß', '‚ò†', '‚ï†', 'üöô', 'üíª', '‚ñÑ', 'üëì', '‚óÑ', 'üîû', '‚óÄ', 'üîô', 'üêΩ', '‚ûî', 'üí∂', '‚ï©', 'üêë', 'üçû', '‚ïö', 'üàπ', 'üê≥', '‚ú™', '‚ñê', '‚ô†', 'üêö', 'üëÇ', 'üóΩ', 'üÜí', 'üê∫', '‚û®', '‚ï¨', 'üåÇ', 'üöå', 'üç°', '‚ù•', 'üé°', 'üê©', '‚åö', 'üêñ', 'üêî', 'üê≤', '‚ùä', 'üö∫', '‚óü', 'üç¢', 'üé®', '‚õ≤', '‚ñÅ', 'üá¥', 'üöï', 'üêà', '‚áß', '‚òé', 'üåÅ', 'üè∞', 'üöµ', 'üéê', '‚ïó', '‚ï±', '‚á©', 'üöÇ', '‚ú¶', '‚õ™', '‚ïî', 'üî±', 'üÜì', '‚ñÇ', 'üöã', 'üåÜ', 'üîπ', 'üê´', 'üè™', '€©', 'üêÇ', '‚ú≥', 'üêÄ', '‚ï¶', 'üêï', '‚úí', 'üè¢', 'üöö', 'üêâ', '‚ùí', 'üêä', 'üöñ', '‚ñº', '‚òõ', '‚ú©', 'üö§', 'üéª', 'üî∑', 'üö¶', '‚úØ', '‚ï£', 'üìÄ', 'üöõ', 'üìì', '‚òâ', 'üí¥', '‚îº', 'üêÉ', 'üçÑ', 'üìï', 'üöì', '‚Ü™', 'üë±', '‚í∂', 'üè®', '‚ôé', 'üî∏', 'üêÜ', '‚ô¢', '‚ó°', 'üìµ', 'üê°', 'üèØ', '‚òÇ', 'üé™', '‚Ü≥', 'üîà', 'üìç', 'üöî', '‚è©', '€û', '‚òæ', 'üì•', 'üî¶', 'üöÅ', 'üêÅ', '‚ôÇ', '‚óû', 'üìØ', '‚óÇ', 'üì∂', 'üö•', 'üåÑ', 'üóæ', 'üî∂', 'üè§', 'üé©', 'üêÖ', '‚ôÆ', 'üîÑ', '‚òÑ', '‚ò®'], 'neg': [':(', ':((', ':(((', ':((((', ':C', ':CC', \":'C\", '=(', '=((', \":'(\", \"='(\", ':[', ':{', '):', 'üò≠', 'üò©', 'üòí', 'üòî', 'üò°', 'üò¥', 'üî´', 'üòû', 'üò™', 'üò´', 'üíÄ', 'üòï', 'üíî', 'üò§', 'üò∞', 'üòë', 'üò†', 'üòì', 'üò£', 'üòê', 'üò®', 'üòñ', 'üëé', 'üò∑', 'üí©', 'üôÖ', 'üòø', 'üò≤', 'üò∂', 'üòß', 'üö´', 'üëê', 'üë¨', 'Ôøº', 'üëø', '‚úÇ', 'üë™', 'üò¶', 'üç£', 'üôç', 'üç±', 'üíß', 'üîã', 'üòæ', 'üç•', '‚öæ', 'üçÆ', 'üëÆ', '‚òπ', '‚î≥', 'üë∫', 'üíÇ', 'üôé', 'üî®', 'üé≠', '‚îà', 'üç†', '‚ñ°', 'üè´', '‚ùî', '‚ñå', '‚ñ†', 'üçà', '‚û∞', 'üîå', '‚îª', '‚è≥', 'üèá', 'üö©', 'üìå', '‚òê', '‚îê', '‚òÆ', 'üîß', 'üÖæ']}, {'fingerbang', 'pillowbiter', 'gaytard', 'queerbait', 'prig', 'pissed', 'titties', 'shit', 'slope', 'group sex', 'goodpoop', 'slanteye', 'dickheads', 'godamnit', 'jizz', 'cyberfucked', 'hentai', 'dickripper', 'booty call', 'pedophilia', 'choad', 'whoar', 'shi+', 'skullfuck', 'herpes', 'lech', 'strap on', 'god-damned', 'wiseass', 'whores', 'boned', 'sodomize', 'spic', 'shittiest', 'tied up', 'arian', 'fucks', 'poonany', '4r5e', 'willies', 'chink', 'condom', 'ass fuck', 'axwound', 'rectus', 'homey', 'assbanger', 'upskirt', 'cuntass', 'cahone', 'pcp', 'nigg3r', 'skank', 'assclown', 'cumming', 'date rape', 'circlejerk', 'gang bang', 'cumslut', 'muthafecker', 'feltcher', 'shamedame', 'chodes', 'transsexual', 'diddle', 'lemon party', 'tight white', 'vorarephilia', 'flange', 'asshole', 'godamn', 'one guy one jar', 'clover clamps', 'scat', 'facial', 'futanari', 'breasts', 'dagos', 'smutty', 'jerk-off', 'n1gga', 'cock pocket', 'cokmuncher', 'jerked', 'moolie', 's.o.b.', 'sambo', 'hore', 'eat a dick', 'dirty', 'motherfuckin', 'shitheads', 'shitcanned', 'cocksucks', 'masterbat3', 'bitch', 'coksucka', 'knob', 'milf', 'dick hole', 'frigg', 'fags', 'knobjokey', 'fcuker', 'muthafuckker', 'gassy ass', 'phuks', 'cyberfuck', 'hitler', 'handjob', 'ball sucking', 'doggy style', 'dirsa', 'cuntslut', 'twunter', 'fuckboy', 'shithead', 'white power', 'phukked', 'piece of shit', 'shitting', 'goldenshower', 'screwed', 'kootch', 'bimbos', 'fuck-ass', 'puss', 'bampot', 'f u c k e r', 'fagged', 'japs', 'nonce', 'cumguzzler', 'fistfuckers', 'bunny fucker', 'polesmoker', 'hooter', 'erotism', 'how to murder', 'masterbat*', 'teez', 'dykes', 'menstruate', 'naked', 'wrinkled starfish', 'jackasses', 'fukker', 'cyalis', 'feltch', 'kondum', 'dp action', 'boob', 'tittie5', 'b1tch', 'asshat', 'willy', 'semen', 'prude', 'ar5e', 'shithouse', 'c.0.c.k', 'butt fuck', 'buttfucka', 'fcuking', 'hookah', 'muffdiving', 'goddamn', 'titwank', 'blumpkin', 'cockmunch', 'cumtart', 'buttfuck', 'turd', 'asses', 'bitches', 'analprobe', 'masterbating', 'phonesex', 'fucker', 'chota bags', 'knobend', 'douchewaffle', 'asswhole', 'ghay', 'dildos', 'crabs', 'spread legs', 'sadism', 'orally', 'freex', 'fvck', 'goatcx', 'muff', 'b!tch', 'ruski', 'jungle bunny', 'pimpis', 'booby', 'gooks', 'penis', 'negro', 'a2m', 'moo moo foo foo', 'cocksucked', 'queero', 'ejaculatings', 'doochbag', 'twatwaffle', 'horny', 'strapon', 'teabagging', 'buttcheeks', 'h0mo', 'ass-hat', 'girls gone wild', 'twatty', 'shitass', 'loin', 'kums', 'gook', 'chinky', 'clunge', 'dickhole', 'brotherfucker', 'bollox', 'sluts', 'porch monkey', 'wet dream', 'dammit', 'h0m0', 'yid', 'bosomy', 'fuck-tard', 'bint', 'muff diver', 'clits', 'cunilingus', 'doggy-style', 'fuckwad', 'anal', 'scag', 'nigg4h', 'gooch', 'honky', 'schizo', 'mothafucks', 'phuq', 'cockknocker', 'fack', 'fingerfucking', 'twathead', 'ejaculating', 'asshead', 'cuntrag', 'dickweasel', 'stiffy', 'nigga', 't1tties', 'hootch', 'stupid', 'a$$hole', 'honkey', 'assfucker', 'cut rope', 'pollock', 'wh0re', 'figging', 'pansy', 'drunk', 'booooooobs', 'tawdry', 'pikey', 'yaoi', 'apeshit', 'motherfuckka', 'maxi', 'hom0', 'fatass', 'mick', 'heshe', 'pedo', 'raunch', 'eat my ass', 'wanker', 'one cup two girls', 'felching', 'dickzipper', 'kunja', 'mofo', 'dickwhipper', 'opiate', 'leather restraint', 'kill', 'midget', 'cocks', 'fuckface', 'golden shower', 'ass-pirate', 'jack off', 'anilingus', 'kummer', 'bollock', 'asslicker', 'nimphomania', 'wench', 'anal leakage', 'dickwod', 'beef curtain', 'violet wand', 'penispuffer', 'queers', 'dimwit', 'assbangs', 'fisty', 'assmonkey', 'cumjockey', 'fondle', 'son-of-a-bitch', 'boners', 'homoerotic', 'spade', \"bang (one's) box\", 'cocain', 'jiz', 'smut', 'fukwit', 'sexual', 'sniper', 'microphallus', 'swinger', 'fagot', 'cretin', 'scrud', 'urinal', 'slut', 'pubic', 'tranny', 'mothafucker', 'b00bs', 'topless', 'floozy', 'niggle', 'azz', 'shiz', 'ball licking', 'cunthunter', 'shibari', 'fudge-packer', 'nazism', 'niggas', 'commie', 'tramp', 's-o-b', 'intercourse', 'chode', 'tea bagging', 'd0uch3', 'goatse', 'raped', 'coprophilia', 'bitchy', 'bondage', 'bestiality', 'retarded', 'rimjaw', 'erect', 'shittier', 'golliwog', 'cunt', 'poop', 'fuckoff', 'fisting', 'asshopper', 'orgasmic', 'phuked', 'pube', 'girl on', 'frenchify', 'cacafuego', 'p0rn', 'black cock', 'junky', 'mof0', 'ejakulate', 'dookie', 'pawn', 'bukkake', 'genitals', 'pee', 'fukkin', 'mothafucka', 'undressing', 'choc ice', 'douchey', 'piss pig', 'hot chick', 'slutkiss', 'dickjuice', 'trumped', 'shithole', 'teets', 'male squirting', 'pissflaps', 'hell', 'doggiestyle', 'fuckedup', 'sexo', 'motherfucking', 'masturbation', 'lesbos', 'cripple', 'poon', 'nutter', 'sperm', 'lameass', 'butt plug', 'diligaf', 'testical', 'reich', 'santorum', 'blue waffle', 'double penetration', 'fuckme', 'donkeyribber', 'kike', 'cunnie', 'bum boy', 'fellatio', 'wrapping men', 'nawashi', 'cockmonkey', 'bumclat', 'fecal', 'kraut', 'bitched', 'goregasm', 'cunt hair', 'cummer', 'fistfucked', 'jap', 'cockass', 'porn', 'paedophile', 'fuckin', 'whorehopper', 'cuntlicker', 'sucking', 'lezza/lesbo', 'wtf', 'cyberfucking', '2 girls 1 cup', 'bitch tit', 'shrimping', 'fuckwhit', 'rectum', 'loins', 'assshole', 'phuk', 'chocolate rosebuds', 'fuckbag', 'vomit', 'dickish', 'pissoff', 'gaysex', 'ginger', 'caca', 'creampie', 'niggaz', 'panooch', 'humping', 'fuck puppet', 'booooobs', 'frotting', 'dominatrix', 'lesbo', 'threesome', 'flaps', 'cum guzzler', 'brunette action', 'jiggerboo', 'spac', 'cockwaffle', 'weenie', 'wop', 'masturbating', 'fucka', 'hard core', 'chincs', 'pissin', 'flog the log', 'bloody hell', 'ovums', 'pisses', 'playboy', 'balls', 'm-fucking', 'felcher', 'fuck', 'douche', 'ball sack', 'menage a trois', 'penetration', 'double dong', 'fingerfucks', 'tongue in a', 'urophilia', 'bestial', 'gfy', 'lusty', 'hussy', 'choade', 'zubb', 'raghead', 'foreskin', 'boobs', 'raper', 'uzi', 'phuking', 'ghey', 'ninny', 'fucknut', 'a54', 'assmunch', 'carpetmuncher', 'feck', 'shiznit', 'poopchute', 'yeasty', 'slag', 'batty boy', 'teste', 'fistfucker', 'cleveland steamer', 'assbanged', 'bastard', 'soused', 'spooge', 'mcfagget', 'd0uche', 'taking the piss', 'lmfao', 'fuckass', 'pms', 'tw4t', 'sex', 'shitbreath', 'herp', 'shaggin', 'fagtard', 'dickslap', 'cawk', 'ejaculates', 'l3itch', 'gangbanged', 'throating', 'rimming', 'cracker', 'dyke', 'clitfuck', 'titfuck', 'tittiefucker', 'fagg', 'pussylicking', 'ma5terbate', 'bitchin', 'dickhead', 'panties', 'bullshitted', 'minge', 'kikes', 'queaf', 'faggots', 'shiting', 'fuck you', 'poopuncher', 'fuck-bitch', 'cumdump', 'gang-bang', 'leper', 'rusty trombone', 'hymen', 'dumass', 'mothafucked', 'eat hair pie', 'thug', 'tubgirl', 'nymphomania', 'shitted', 'valium', 'womb', 'fartknocker', 'jism', 'towelhead', 'missionary position', 'coccydynia', 'd1ldo', 'how to murdep', 'scrot', 'massa', 'gender bender', 'son of a motherless goat', 'assbandit', 'stoned', 'rumprammer', 'virgin', 'areole', 'sh!+', 'paki', 'rapey', 'bumblefuck', 'fuckstick', 'blonde action', 'coonnass', 'ball gravy', 'nobjocky', 'damnit', 'crack', 'bung', 'anus', 'rimjob', 'kafir', 'barenaked', 'dingle', 'fucktart', 'nut butter', 'weed', 'camel toe', 'blowjobs', 'whoreface', 'baby juice', 'dry hump', 'hooker', 'beaver lips', 'dink', 'nut sack', 'fuckwit', 'bum', 'hoare', 'dog style', 'psycho', 'whorehouse', 'dogging', 'fuc', 'jerk', 'shite', 'nsfw images', 'cocksuckers', 'alabama hot pocket', 'tosser', 'motherfucked', 'cunt-struck', 'ma5terb8', 'cockfucker', 'spiks', 'pole smoker', 'daterape', 'skag', 'nimrod', 'asssucker', 'shitstain', 'gringo', 'nob', 'bellend', 'jerk off', 'bod', 'beaner', 'coon', 'ho', 'ovary', 'shitfull', 'dicks', 'twat', 'crotte', 'how to kill', 'hot carl', 'seamen', 'wiseasses', 'tushy', 'cumshots', 'punta', 'assfaces', 'opium', 'racy', 'mong', 'barf', 'dickweed', 'fuck hole', 'fuckbutter', 'faig', 'fuk', 'sleazy', 'trashy', 'cocknugget', 'wang', 'quim', 'hoar', 'fucktoy', 'polack', 'snuff', 'whiz', 'cuntlicking', 'shitdick', 'heeb', 'jackass', 'guro', 'penial', 'fucking', 'erection', 'arsehole', 'punanny', 'biatch', 'asspirate', 'lolita', 'beaners', 'labia', 'doggie-style', 'pissing', 'bloodclaat', 'sandnigger', 'pedophiliac', 'leather straight jacket', 'shitey', 'scissoring', 'spook', 'pussys', 'shitfuck', 'f.u.c.k', 'booobs', 'cock snot', 'booger', 'fuck yo mama', 'cockmuncher', 'testee', 'fudge packer', 'crackwhore', 'ahole', 'scantily', 'penisbanger', 'deepthroat', 'mothafuckaz', 'nutsack', 'ball kicking', 'cockburger', 'cocksukka', 'cuntsicle', 'gey', 'coochy', 'c-o-c-k', 'orgasms', 'boozer', 'buttmuch', 'fuckhead', 'dlck', 'dick shy', 'gae', 'sandbar', 'f_u_c_k', 'beatch', 'faggot', 'tittyfucker', 'cocksniffer', 'fxck', 'bdsm', 'knobhead', 'bummer', 'pegging', 'toke', 'klan', 'lovemaking', 'cunillingus', 'cyberfucker', 'dumbasses', 'blowjob', 'motherfucka', 'knob end', 'doggie style', 'taig', 'cockknoker', 'sissy', 'cocksmith', 'rtard', 'wetback', 'ritard', 'taff', 'bareback', 'a_s_s', 'bullshits', 'tittywank', 'jizzed', 'fuck off', 'asscock', 'boobies', 'gonad', 'juggs', 'gokkun', 'strip club', 'tit', 'fucked', 'buttmunch', 'gaywad', 'assfukka', 'iap', 'a$$', 'vixen', 'pussy', 'screw', 'godsdamn', 'jackhole', 'fingerfucker', 'female squirting', 'bitchers', 'fukkers', 'penetrate', 'pornography', 'wigger', 'pricks', 'dipshit', 'cocksmoke', 'niggah', 'weiner', 'vagina', 'bastardo', 'dingleberries', 'kunilingus', 'tribadism', 'dicksucker', 'queerhole', 'bigtits', 'mr hands', 'pantie', 'nympho', 'autoerotic', 'kinbaku', 'bawdy', 'ponyplay', 'douche-fag', 'damn', 'dumbfuck', 'kwif', 'munging', 'bitchass', 'fuckup', 'fenian', 'c.o.c.k.', 'prostitute', 'chi-chi man', 'big breasts', 'ecchi', 'nipple', 'cockjockey', 'sanger', 'sausage queen', 'toots', 'fuckbutt', 'cockshit', 'jelly donut', 'boiolas', 'make me come', 'foah', 'glans', 'swastika', 'donkey punch', 's_h_i_t', 'gayfuck', 'c-0-c-k', 'zibbi', 'fagging', 'schlong', 'taste my', 'pthc', 'clit', 'cumdumpster', 'assshit', 'shitcunt', 'ganja', 'cameltoe', 'mothafuck', 'a55hole', 'eunuch', 'foot fetish', 'rectal', 'shitings', 'shota', 'clitorus', 'napalm', 'dick-ish', 'son of a bitch', 'fannybandit', 'middle finger', 'bollok', 'cumshot', 'bung hole', 'testis', 'old bag', 'god', 'muther', 'sleaze', 'strappado', 'poop chute', 'boong', 'huge fat', 'big tits', 'assmaster', 'dommes', 'revue', 'clitty litter', 'grope', 'assnigger', 'dickwad', 'cnut', 'master-bate', 'assholes', 'homoey', 'fucknutt', 'masturbate', 'dillweed', 'cock sucker', 'lmao', 'cuntbag', 'dipship', 'd0ng', 'cooter', 'fooker', 'reetard', 'souse', 'gash', 'cocksmoker', 'urethra play', 'shag', 'bosom', 'motherfucker', 'm0f0', 'tainted love', 'dawgie-style', 'cockmongler', 'cyberfuckers', 'motherfuck', 'whored', 'faggitt', 'jizm', 'pisser', 'assmucus', 'mothafucking', 's-h-i-t', 'dvda', 'jerkoff', 'pissers', 'zoophilia', 'fingerfuckers', 'bull shit', 'shittings', 'hardcoresex', 'breeder', 'v14gra', 'cuntface', 'bastinado', 'dummy', 'ejaculate', 'smartasses', 'nig-nog', 'fuckmeat', 'lezzie', 'prickteaser', 'sexy', 'cyberfuc', 'chick with a dick', 'fagots', 'raging boner', 'dirty sanchez', 'arse', 'coochie', 'whore', 'kunt', 'dago', 'fannyfucker', 'wad', 'wog', 'orgasims', 'dickbeaters', 'nappy', 'phallic', 'spick', 'menses', 'clit licker', 'coprolagnia', 'dumb ass', 'p.u.s.s.y.', 'horniest', 'pedobear', 'giant cock', 'chinc', 'aeolus', 'blonde on blonde action', 'unwed', 'shaved pussy', 'cocksuka', 'a55', 'escort', 'pissed off', 'gangbang', 'shitbrains', 'weewee', 'hooch', 'strip', 'fucktards', 'sand nigger', 'va-j-j', 'munter', 'dingleberry', 'pecker', 'rum', 'crap', 'knobjocky', 'len', 'seks', 'frigga', 'kum', 'mafugly', 'corpulent', 'dike', 'cl1t', 'boner', 'cocksucking', 'hemp', 'fagfucker', 'cocklump', 'bullturds', 'wanky', 'bullet vibe', 'acrotomophilia', 'm45terbate', 'hooters', 'nig nog', 'bunghole', 'faigt', 'jack-off', 'ass-jabber', 'rubbish', 'goddamned', 'lesbian', 'meth', 'scrotum', 's&m', 'shitbag', 'cum chugger', 'pot', 'brown showers', 'fingering', 'yellow showers', 'yiffy', 'masochist', 'mutherfucker', 'gspot', 'whorebag', 'essohbee', 'prince albert piercing', 'bulldyke', 'fistfuckings', 'neonazi', 'thundercunt', 'ugly', 'x-rated', 'assgoblin', 'whoralicious', 'mo-fo', 'duche', 'bloody', 'child-fucker', 's.h.i.t.', 'smartass', 'shiteater', 'beef curtains', 'gayass', 'moron', 'nude', 'whorealicious', 'f4nny', 'lardass', 'gonads', 'cockmaster', 'beastial', 'twunt', 'assfuck', 'dumbass', 'nudity', 'dick head', 'doublelift', 'screwing', 'slutdumper', 'masterbation', 'coffin dodger', 'ovum', 'punkass', 'bollocks', 'dildo', 'mound of venus', 'ass hole', 'cornhole', 'babeland', 'deggo', 'vajayjay', 'bootee', 'cumbubble', 'fuck trophy', 'rosy palm and her 5 sisters', 'lust', 'shitblimp', 'cum', 'pleasure chest', 'fanyy', 'pedophile', 'pimp', 'big black', 'masterbations', 'fucktard', 'w00se', 'gaybob', 'poontang', 'faggs', 'fist fuck', 'goddamnit', 'weirdo', 'fuker', 'kooch', 'sh1t', 'renob', 'snowballing', 'xxx', 'queef', 'dickfuck', 'omg', 'booze', 'sucks', '2g1c', 'dendrophilia', 'suckass', 'kumming', 'cunnilingus', 'booty', 'assbag', 'areola', 'fuks', 'fuckwitt', 'cockbite', 'ballbag', 'jagoff', 'knobead', 'cum dumpster', 'splooge', 'blow me', 'ham flap', 'doggin', 'donkeypunch', 'fisted', 'twatlips', 'cocksuck', 'hoer', 'omorashi', 'birdlock', 'urine', 'inbred', 'unclefucker', 'mutha', 'shitfaced', 'dumbshit', 'doosh', 'shitty', 'cumstain', 'knobbing', 'blow your load', 'girl on top', 'buttfucker', 'douch3', 'murder', 'm0fo', 'blow job', 'f-u-c-k', 'phuck', 'fice', 'footjob', 'punani', 'pusse', 'dick', 'aryan', 'chesticle', 'fucktwat', 'fukwhit', 'kinkster', 'vjayjay', 'extasy', 'jerk0ff', 'c0cksucker', 'buceta', 'alaskan pipeline', 'cok', 'fleshflute', 'fuckhole', 'rosy palm', 'jail bait', 'beotch', 'dickmilk', 'peepee', 'suicide girls', 'dicksipper', 'b17ch', 'carpet muncher', 'orgasm', 'beastiality', 'butt', 'dopey', 'fuckheads', 'hoe', 'teat', 'nob jokey', 'fannyflaps', 'bangbros', 'sh!t', 'div', 'assjacker', 'cockface', 'snatch', 'dickface', 'pisspig', 'god damn', 'ejaculation', 'bootie', 'dong', 'thrust', 'octopussy', 'jaggi', 'nazi', 'r-tard', 'kock', 'dick-sneeze', 'cockeye', 'numbnuts', 'shitspitter', 'uterus', 'feist', 'injun', 'penisfucker', 'nambla', 'cox', 't1t', 'xrated', 'fuckersucker', 'shemale', 'twinkie', 'goddammit', 'xx', 'fuck buttons', 'cockholster', 'faggit', 'azazel', 'fuckbrain', 'bastards', 'hand job', 'homodumbshit', 'c0ck', 'titi', 's0b', 'lesbians', 'shitters', 'shit ass', 'sucked', 'cum freak', 'bi+ch', 'jigaboo', 'shirt lifter', 'nigaboo', 'window licker', 'motherfuckers', 'beardedclam', 'beaver cleaver', 'fagbag', 'wankjob', 'molest', 'holy shit', 'kondums', 'vibrator', 'wazoo', 'herpy', 'motherfucks', 'shited', 'nipples', 'twink', 'fistfucks', 'asslick', 'scroat', 'blow mud', 'flamer', 'buncombe', 'seduce', 's-h-1-t', 'ballsack', 'bimbo', 'shitt', 'cums', 'gaydo', 'git', 'c.u.n.t', 'barely legal', 'fistfuck', 'corksucker', 'rapist', 'dog-fucker', 'mother fucker', 'bust a load', 'sandler', 'cock-sucker', 'asswad', 'lube', 'hircismus', 'cunts', 'piss', 'son of a whore', 'poonani', 'shit fucker', 'lez', 'tard', 'doofus', 'arrse', 'perversion', 'piss-off', 'darn', 'fingerfucked', 'dumshit', 'camgirl', 'kawk', 'fag', 'rape', 'dirty pillows', 'orgasim', 'ass-fucker', 'foobar', 'assbang', 'tart', 'bullshit', 'poof', 'undies', 'goddam', 'prick', 'incest', 'skeet', 'bitcher', 'faggotcock', 'mams', 'minger', 'crikey', 'he-she', 'shagger', 'dickbag', 'slut bucket', 'wedgie', 'porno', 'gay', 'slave', 'organ', 'erotic', 'l3i+ch', 'cunthole', 'veqtable', 'boink', 'punany', 'quicky', 'fuckingshitmotherfucker', 'stroke', 'vodka', 'pussy palace', 'cunny', 'bitchtits', 'whoring', 'clitty', 't1tt1e5', 'deep throat', 'dickmonger', 'lusting', 'douchebag', 'assmuncher', 'asswipe', 'junkie', 'crappy', 'junglebunny', 'mothafuckers', 'cipa', 'orgies', 'reverse cowgirl', 'fucknugget', 'voyeur', 'dickdipper', 'clitface', 'menstruation', 'vulgar', 'butt-pirate', 'splooge moose', 'boozy', 'dolcett', 'humped', 'hiv', 'cockblock', 'sodomy', 'bookie', 'smegma', 'coital', 'fecker', 'knobed', 'gangbangs', 'scum', 'sultry women', 'fux', 'bugger', 'douchebags', 'jock', 'ass', 'gay sex', 'jiggaboo', 'hoor', 'god-dam', 'clitoris', 'bescumber', 'gigolo', 'assbite', 'domination', 'two girls one cup', 'hebe', 'two fingers with tongue', 'wh0reface', 'gayfuckist', 'potty', 'gays', 'goo girl', 'vulva', 'femdom', 'kyke', 'twats', 'fubar', 'boooobs', 'busty', 'seaman', 'muffdiver', 'beeyotch', 'fook', 'shitbagger', 'shits', 'fudgepacker', 'cop some wood', 'bender', 'orgy', 'sadist', 'ninnyhammer', 'sodom', 'camwhore', 'pussypounder', 'tush', 'spunk', 'cocksucker', 'sod off', 'extacy', 'c-u-n-t', 'fanny', 'fux0r', 'stfu', 'pubes', 'gtfo', 'muff puff', 'nobhead', 'scrote', 'ball gag', 'tampon', 'dicksucking', 'heroin', 'shagging', 'v1gra', 'iberian slap', 'assface', 'hobag', 'tinkle', 'raping', 'cocaine', 'pornos', 'tits', 'fuckings', 'tittyfuck', 'looney', '5hit', 'peckerhead', 'bitching', 'dumbcunt', 'n1gger', 'panty', 'spik', 'felch', 'yobbo', 'prod', 'butthole', 'cuntlick', 'asswipes', 'pubis', 'penile', 'venus mound', 'need the dick', 'titty', 'cus', 'dickfucker', 'kinky', 'climax', 'd1ld0', 'gai', 'porchmonkey', 'cockmongruel', 'pinko', 'scrog', 'hardcore', 'big knockers', 'f u c k', 'corp whore', 'cock', 'mothafuckin', 'auto erotic', 'fart', 'shitter', 'dicktickler', 'reefer', 'dickflipper', 'assho1e', 'beaver', 'd1ck', 'sumofabiatch', 'doggystyle', 'cockhead', 'queer', 'coons', 'anal impaler', 'gaylord', 'kooches', 'niggers', '5h1t', 'slutbag', 'assh0le', 'darkie', 'pussy fart', 'foad', 'asscracker', 'suck', 'pussies', 'wank', 'two fingers', 'bbw', 'fistfucking', 'pigfucker', 'puto', 'rump', 'titt', 'fcuk', 'retard', 'nigger', 'gippo', 'fuckers', 'baby batter', 'pussi', 'g-spot', 'tit wank', 'masterbate', 'mothafuckas', 'camslut', 'tub girl', 'hard on', 'jackoff', 'vag', 'motherfuckings', 'guido', 'cervix', 'cocknose', 'testicle', 's hit', 'jailbait', 'jerkass', 'fellate', 'punky', 'niglet', 'viagra', 'phukking', 'pust', 'hun', 'he11', 'piss off', 'bong', 'fingerfuck', 'smeg', 'testes', 'masterb8', 'style doggy', 'bodily', 'damned', 'cummin', 'clusterfuck', 'shitface', 'homo', 'hotsex', 'pron', 'shaved beaver', 'tities', 'dinks', 'ejaculated', 'buttplug', 'fuq', 'hump', 'nobjokey', 'mothafuckings', 'phone sex'}, {'able', 'follows', 'home', 'otherwise', 'predominantly', 'again', 'et-al', 'regards', 'wed', 'downwards', 'related', 'self', 'aren', 'ie', 'h', 'meanwhile', 'five', 'wasnt', 'got', 'somewhere', 'hers', \"they've\", 'plus', 'mg', 'may', 'down', 'g', 'your', 'a', 'back', 'about', 'whatever', 'whence', 'anything', 'ref', 'last', 'largely', 'almost', 'twice', 'nearly', 'nay', 'taking', 'slightly', 'afterwards', 'herein', \"don't\", 'also', 'except', 'i', 'together', 'sufficiently', \"doesn't\", 'significantly', 'same', 'seem', 'trying', 'which', \"we'll\", 'shows', 'against', 'different', 'obtain', 'since', 'up', 'k', 'eg', 'likely', 'previously', 'edu', 'former', 'myself', 'vol', 'another', 'readily', 'even', 'formerly', 'wheres', 'inward', 'and', 'becoming', 'must', 'usefully', 'wish', 'wants', 'might', 'necessary', 'showns', 'for', 'whither', 'whom', 'have', 'everything', 'go', 'saying', 'sometimes', 'itself', 'lets', 'onto', 'tell', \"i've\", 'he', 'but', 'useful', 'owing', 'cause', 'unto', 'nd', 'y', 'everyone', 'til', 'across', 'when', \"there'll\", 'namely', 'various', 'thereafter', 'contains', 'immediately', 'relatively', 'yet', 'refs', 'hereby', 'adj', 'keep', 'importance', 'vs', 'among', 'what', 'whereupon', 'b', 'whole', 'nowhere', 'que', 'whereas', 'else', 'mainly', 'announce', 'gave', 'my', 'theyre', 'hundred', 'id', 'first', 'obtained', 'ex', 'fifth', 'poorly', 'alone', 'goes', 'quite', 'zero', 'particular', 'want', 'can', 'should', 'becomes', 'seemed', 'those', 'j', 'off', 'through', 'kept', 'part', 'research', 'soon', 'out', 'to', 'me', 'youd', 'once', 'most', 'mostly', 'certainly', 'usually', 'both', 'moreover', 'take', 'important', 'here', 'noone', 'biol', \"she'll\", 'couldnt', 'put', 'few', \"i'll\", 'willing', 'uses', 'this', 'hid', 'give', 'gone', 'would', 'date', 'his', 'indeed', 'shown', 'think', 'due', 'widely', 'lest', 'selves', 'unlike', 'new', 'from', 'more', 'approximately', 'used', 'anywhere', 'all', 'run', 'primarily', 'past', 'com', 'anyways', 'accordingly', 's', 'no', 'though', 'keeps', 'ought', 'besides', 'comes', 'each', 'ups', 'th', 'between', 'page', 'please', 'specify', 'like', 'look', 'try', 'potentially', 'at', 'throug', 'oh', 'according', 'thereupon', 'why', 'beforehand', 'next', 'be', 'section', 'showed', 'recent', 'ran', 'nor', 'im', 'it', 'do', 'significant', 'too', 'begins', 'believe', 'upon', 'hereupon', 'now', 'v', 'known', 'looks', 'whim', 'either', 'similarly', 'themselves', 'needs', 'during', 'let', 'say', 'beside', 'using', 'following', 'in', 'although', 'little', 'promptly', 'therefore', 'thereof', 'just', \"that've\", 'line', 'with', 'took', 'm', 'our', 'nobody', 'overall', 'within', 'theyd', 'after', 'anymore', 'awfully', 'herself', 'we', 'welcome', 'substantially', 'ca', 'mug', 'anyhow', 'doing', 'hereafter', 'others', 'pages', 'given', 'auth', 'fix', 'ninety', \"that'll\", 'being', 'furthermore', 'could', 'e', 'normally', 'world', 'knows', 'then', 'always', 'thered', 'whereafter', 'without', 'accordance', 'hence', 'probably', 'least', 'thereby', 'means', \"what'll\", 'necessarily', 'similar', 'something', 'unlikely', 'ed', 'regardless', 'outside', 'therein', 'done', 'did', 'really', 'somebody', 'says', \"you've\", 'that', 'resulted', 'until', 'lately', 'thus', 'so', 'end', 'had', 'getting', 'actually', 'own', 'around', 't', 'ask', 'under', 'particularly', 'shes', \"it'll\", 'vols', 'forth', 'sub', 'hi', 'beyond', 'ending', 'they', 'nine', 'inc', 'much', 'information', 'who', 'thats', 'etc', 'hes', \"we've\", \"they'll\", 'un', 'him', 'value', 'whats', 'by', \"hasn't\", 'himself', 'ord', 'stop', 'f', 'ourselves', 'far', 'toward', 'wouldnt', 'hardly', 'many', 'several', 'thousand', 'd', 'use', 'there', 'begin', 'was', 'maybe', 'rather', 'still', 'while', 'ones', 'ff', 'obviously', 'thank', 'u', 'wherein', 'you', 'specifically', 'whoever', 'said', 'howbeit', 'hed', 'seen', \"you'll\", 'looking', 'such', 'et', 'its', 'less', 'thou', 'whose', 'respectively', 'elsewhere', 'yourself', 'sup', 'kg', 'perhaps', 'only', 'the', 'itd', 'theirs', 'shall', 'especially', 'mrs', 'taken', \"'ve\", 'whomever', 'anyone', 'four', 'yourselves', 'x', 'omitted', 'arent', 'invention', 'per', 'way', \"haven't\", 'name', 'an', 'truly', 'results', 'strongly', 'affects', 'get', 'ok', 'instead', 'latterly', 'specified', 'other', 'seven', 'q', 'does', 'above', 'whereby', 'brief', 'viz', 'eighty', 'tried', 'tip', 'abst', 'see', 'sorry', 'asking', \"'ll\", 'how', 'rd', 'eight', 'pp', 'miss', 'enough', 'somewhat', 'effect', \"who'll\", 'thence', 'ah', 'possible', 'already', 'wherever', 'quickly', 'because', 'containing', 'none', 'us', 'am', 'million', 'tends', 'gotten', 'throughout', 'ts', 'found', 'c', 'everybody', 'nevertheless', 'some', 'sure', 'often', 'these', 'became', 'towards', 'available', 'came', 'successfully', 'anyway', 'km', 'w', 'whod', 'proud', 'present', 'latter', 'werent', 'happens', 'o', 'six', 'tries', 'become', 'thoughh', 'contain', 'near', 'come', 'nothing', 'resulting', 'neither', 'aside', 'heres', 'not', \"can't\", 'along', 'na', 'below', 'or', 'than', 'as', 'wont', 'are', 'possibly', 'someone', 'yes', 'nonetheless', 'z', 'she', 'thereto', 'made', 'very', 'meantime', 'on', 'somehow', 'unfortunately', 'everywhere', 'okay', 're', 'liked', 'added', \"there've\", 'causes', 'seeming', 'cannot', 'www', 'hither', 'whether', 'know', \"shouldn't\", 'theres', 'two', 'saw', 'usefulness', 'later', 'been', 'youre', 'noted', 'anybody', 'apparently', 'away', 'amongst', 'affected', 'into', 'makes', 'old', 'any', 'if', 'ours', 'whenever', 'seeing', \"didn't\", 'went', 'gets', 'beginning', 'mr', 'where', 'of', 'whos', 'provides', 'before', 'her', 'via', 'shed', 'thanks', 'sometime', \"isn't\", 'unless', 'qv', 'suggest', 'never', 'therere', 'placed', 'p', 'further', 'non', 'nos', 'arise', 'n', 'specifying', 'having', 'certain', 'show', 'briefly', 'words', 'l', 'were', 'act', 'affecting', 'yours', 'giving', 'need', 'recently', 'behind', 'mean', 'ltd', 'followed', 'thanx', 'ever', 'r', 'immediate', 'seems', 'is', 'however', 'right', 'co', 'merely', 'index', 'beginnings', 'regarding', 'their', 'ml', 'has', 'make', 'somethan', 'over', 'one', 'thru', 'them', 'every', 'gives', 'sent', 'sec'}]\n"
     ]
    }
   ],
   "source": [
    "# https://blog.cambridgespark.com/50-free-machine-learning-datasets-sentiment-analysis-b9388f79c124\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words\n",
    "# https://www.aclweb.org/anthology/W18-2502/\n",
    "def stopwords():\n",
    "    import os\n",
    "    root_path = f\"/home/halpdesk/CODE/reddit-parser\"\n",
    "    filename = f\"{root_path}/datasets/ranksnl_large.csv\"\n",
    "    stop_words = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            for word in line.split(\",\"):\n",
    "                stop_words.append(word.lower().strip())\n",
    "    return set(stop_words)\n",
    "\n",
    "def badwords():\n",
    "    import os\n",
    "    root_path = f\"/home/halpdesk/CODE/reddit-parser\"\n",
    "    filename = f\"{root_path}/datasets/fb-bad-words.csv\"\n",
    "    bad_words = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            for word in line.split(\",\"):\n",
    "                bad_words.append(word.lower().strip())\n",
    "    return set(bad_words)\n",
    "\n",
    "# From https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144296:\n",
    "# http://kt.ijs.si/data/Emoji_sentiment_ranking/\n",
    "# Other: https://research.utwente.nl/files/5482763/sac13-senticon.pdf\n",
    "# http://emojitracker.com/\n",
    "def emoticons():\n",
    "    import os\n",
    "    root_path = f\"/home/halpdesk/CODE/reddit-parser\"\n",
    "    filename = f\"{root_path}/datasets/emoticons.csv\"\n",
    "    emoticons = {\n",
    "        \"pos\": [\":)\", \":))\", \":D\", \":DD\", \"xD\", \"xDD\", \":d\" \"=)\", \"=))\", \":')\", \"=')\", \":}\", \":}}\", \":]\", \":]]\", \"(:\", \"C:\", \":P\"],\n",
    "        \"neu\": [\":|\", \":/\", \":\\\\\", \"\"],\n",
    "        \"neg\": [\":(\", \":((\", \":(((\", \":((((\", \":C\", \":CC\", \":'C\", \"=(\", \"=((\", \":'(\", \"='(\", \":[\", \":{\", \"):\"]\n",
    "    }\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            word = line.split(\",\")\n",
    "            smil = word[0]\n",
    "            #unicodesmil = chr(int(word[1], 0))\n",
    "            neg = float(word[3])\n",
    "            neu = float(word[4])\n",
    "            pos = float(word[5])\n",
    "            if neu > pos and neu > neg:\n",
    "                emoticons[\"neu\"].append(smil)\n",
    "            elif pos > neg:\n",
    "                emoticons[\"pos\"].append(smil)\n",
    "                #emoticons[\"pos\"].append(unicodesmil)\n",
    "            else:\n",
    "                emoticons[\"neg\"].append(smil)\n",
    "    return emoticons\n",
    "\n",
    "print([emoticons(), badwords(), stopwords()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                           submission  \\\n0   The author Tolkiens son has released a new fan...   \n1   The author Tolkiens son has released a new fan...   \n2   The author Tolkiens son has released a new fan...   \n3   The author Tolkiens son has released a new fan...   \n4   The author Tolkiens son has released a new fan...   \n5   The author Tolkiens son has released a new fan...   \n6   The author Tolkiens son has released a new fan...   \n7   The author Tolkiens son has released a new fan...   \n8   The author Tolkiens son has released a new fan...   \n9   The author Tolkiens son has released a new fan...   \n10  The author Tolkiens son has released a new fan...   \n11  The author Tolkiens son has released a new fan...   \n12  The author Tolkiens son has released a new fan...   \n13  The author Tolkiens son has released a new fan...   \n14  The author Tolkiens son has released a new fan...   \n15  The author Tolkiens son has released a new fan...   \n\n                                                 body  \n0   Hey Tommy the blue, this is a great book for y...  \n1   Awesome books! Awesome author! Where did you g...  \n2   I hate this author :C he is really bad he can ...  \n3   No way! The blue wizards finally got a book?? ...  \n4   Fantasy is boring :/. I'd rather dive into som...  \n5    :D:D YEY!! *amazing* werent they supposed to be?  \n6               this is an old bag with herpes book üëé  \n7                             this wook I like üíöüíöüíö !!  \n8                              marry this book I will  \n9   if you are going to buy this book, make sure y...  \n10                             how much does it cost?  \n11                                      I can pay $$$  \n12          loooooooooooooooooooooooooooool trolololo  \n13  The authors son has released a new fantasy ser...  \n14                                author, blue wizard  \n15  marry fantasy blue Nietzsche awsome Tommy trol...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Hey Tommy the blue, this is a great book for y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Awesome books! Awesome author! Where did you g...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>I hate this author :C he is really bad he can ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>No way! The blue wizards finally got a book?? ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Fantasy is boring :/. I'd rather dive into som...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>:D:D YEY!! *amazing* werent they supposed to be?</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>this is an old bag with herpes book üëé</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>this wook I like üíöüíöüíö !!</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>marry this book I will</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>if you are going to buy this book, make sure y...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>how much does it cost?</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>I can pay $$$</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>loooooooooooooooooooooooooooool trolololo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>The authors son has released a new fantasy ser...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>author, blue wizard</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>marry fantasy blue Nietzsche awsome Tommy trol...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = \"The author Tolkiens son has released a new fantasy series! The first book is about the Blue wizards! OMG YOU HAVE TO BUY :D:D\"\n",
    "sentences = [\n",
    "    \"Hey Tommy the blue, this is a great book for you üòÅüíö\",\n",
    "    \"Awesome books! Awesome author! Where did you get it? :)\",\n",
    "    \"I hate this author :C he is really bad he can go and ugly himself ugly\",\n",
    "    \"No way! The blue wizards finally got a book?? OMG I have to buy it xD üëª\",\n",
    "    \"Fantasy is boring :/. I'd rather dive into some Nietzsche and I think everyone should\",\n",
    "    \":D:D YEY!! *amazing* werent they supposed to be?\",\n",
    "    \"this is an old bag with herpes book üëé\",\n",
    "    \"this wook I like üíöüíöüíö !!\",\n",
    "    \"marry this book I will\",\n",
    "    \"if you are going to buy this book, make sure you get it at towns hall because they have extra t-shirts!\",\n",
    "    \"how much does it cost?\",\n",
    "    \"I can pay $$$\",\n",
    "    \"loooooooooooooooooooooooooooool trolololo\",\n",
    "    \"The authors son has released a new fantasy series! The first book is about the Blue wizards! OMG YOU HAVE TO BUY :D:D\",\n",
    "    \"author, blue wizard\",\n",
    "    \"marry fantasy blue Nietzsche awsome Tommy trolololo\",\n",
    "]\n",
    "df = pd.DataFrame({\"submission\": [submission for i in range(len(sentences))], \"body\": sentences})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           submission  \\\n",
       "0   The author Tolkiens son has released a new fan...   \n",
       "1   The author Tolkiens son has released a new fan...   \n",
       "2   The author Tolkiens son has released a new fan...   \n",
       "3   The author Tolkiens son has released a new fan...   \n",
       "4   The author Tolkiens son has released a new fan...   \n",
       "5   The author Tolkiens son has released a new fan...   \n",
       "6   The author Tolkiens son has released a new fan...   \n",
       "7   The author Tolkiens son has released a new fan...   \n",
       "8   The author Tolkiens son has released a new fan...   \n",
       "9   The author Tolkiens son has released a new fan...   \n",
       "10  The author Tolkiens son has released a new fan...   \n",
       "11  The author Tolkiens son has released a new fan...   \n",
       "12  The author Tolkiens son has released a new fan...   \n",
       "13  The author Tolkiens son has released a new fan...   \n",
       "14  The author Tolkiens son has released a new fan...   \n",
       "15  The author Tolkiens son has released a new fan...   \n",
       "\n",
       "                                                 body  top-cos-sim   cos-sim  \\\n",
       "0   Hey Tommy the blue, this is a great book for y...     0.124544  0.347250   \n",
       "1   Awesome books! Awesome author! Where did you g...     0.292932  0.300376   \n",
       "2   I hate this author :C he is really bad he can ...     0.111172  0.257702   \n",
       "3   No way! The blue wizards finally got a book?? ...     0.350607  0.386542   \n",
       "4   Fantasy is boring :/. I'd rather dive into som...     0.089181  0.299210   \n",
       "5    :D:D YEY!! *amazing* werent they supposed to be?     0.235832  0.232469   \n",
       "6               this is an old bag with herpes book üëé     0.074712  0.247595   \n",
       "7                             this wook I like üíöüíöüíö !!     0.284917  0.238241   \n",
       "8                              marry this book I will     0.078936  0.237155   \n",
       "9   if you are going to buy this book, make sure y...     0.254673  0.375846   \n",
       "10                             how much does it cost?     0.000000  0.201297   \n",
       "11                                      I can pay $$$     0.000000  0.160905   \n",
       "12          loooooooooooooooooooooooooooool trolololo     0.000000  0.216147   \n",
       "13  The authors son has released a new fantasy ser...     1.000000  0.410480   \n",
       "14                                author, blue wizard     0.460399  0.210884   \n",
       "15  marry fantasy blue Nietzsche awsome Tommy trol...     0.159256  0.372894   \n",
       "\n",
       "    tfidf-mean  wc  wc2  sw  bw  smil+  smil-  smil&  \n",
       "0     0.199697   6    5   6   0      2      0      0  \n",
       "1     0.170570   8    3   5   0      1      0      0  \n",
       "2     0.115405   3    3  11   2      0      1      0  \n",
       "3     0.152297  10    5   9   1      1      0      1  \n",
       "4     0.152450   6    4  10   0      0      0      1  \n",
       "5     0.183981   6    2   6   0      2      0      0  \n",
       "6     0.217263   3    2   5   1      0      1      0  \n",
       "7     0.246456   4    1   3   0      3      0      0  \n",
       "8     0.337679   3    3   2   0      0      0      0  \n",
       "9     0.117474   7    4  15   0      0      0      0  \n",
       "10    0.232337   2    1   4   0      0      0      0  \n",
       "11    0.333333   1    1   2   0      0      0      0  \n",
       "12    0.705429   2    2   0   0      0      0      0  \n",
       "13    0.124816  11    6  14   1      2      0      0  \n",
       "14    0.575771   3    3   0   0      0      0      0  \n",
       "15    0.375381   7    7   0   0      0      0      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission</th>\n      <th>body</th>\n      <th>top-cos-sim</th>\n      <th>cos-sim</th>\n      <th>tfidf-mean</th>\n      <th>wc</th>\n      <th>wc2</th>\n      <th>sw</th>\n      <th>bw</th>\n      <th>smil+</th>\n      <th>smil-</th>\n      <th>smil&amp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Hey Tommy the blue, this is a great book for y...</td>\n      <td>0.124544</td>\n      <td>0.347250</td>\n      <td>0.199697</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Awesome books! Awesome author! Where did you g...</td>\n      <td>0.292932</td>\n      <td>0.300376</td>\n      <td>0.170570</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>I hate this author :C he is really bad he can ...</td>\n      <td>0.111172</td>\n      <td>0.257702</td>\n      <td>0.115405</td>\n      <td>3</td>\n      <td>3</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>No way! The blue wizards finally got a book?? ...</td>\n      <td>0.350607</td>\n      <td>0.386542</td>\n      <td>0.152297</td>\n      <td>10</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>Fantasy is boring :/. I'd rather dive into som...</td>\n      <td>0.089181</td>\n      <td>0.299210</td>\n      <td>0.152450</td>\n      <td>6</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>:D:D YEY!! *amazing* werent they supposed to be?</td>\n      <td>0.235832</td>\n      <td>0.232469</td>\n      <td>0.183981</td>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>this is an old bag with herpes book üëé</td>\n      <td>0.074712</td>\n      <td>0.247595</td>\n      <td>0.217263</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>this wook I like üíöüíöüíö !!</td>\n      <td>0.284917</td>\n      <td>0.238241</td>\n      <td>0.246456</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>marry this book I will</td>\n      <td>0.078936</td>\n      <td>0.237155</td>\n      <td>0.337679</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>if you are going to buy this book, make sure y...</td>\n      <td>0.254673</td>\n      <td>0.375846</td>\n      <td>0.117474</td>\n      <td>7</td>\n      <td>4</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>how much does it cost?</td>\n      <td>0.000000</td>\n      <td>0.201297</td>\n      <td>0.232337</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>I can pay $$$</td>\n      <td>0.000000</td>\n      <td>0.160905</td>\n      <td>0.333333</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>loooooooooooooooooooooooooooool trolololo</td>\n      <td>0.000000</td>\n      <td>0.216147</td>\n      <td>0.705429</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>The authors son has released a new fantasy ser...</td>\n      <td>1.000000</td>\n      <td>0.410480</td>\n      <td>0.124816</td>\n      <td>11</td>\n      <td>6</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>author, blue wizard</td>\n      <td>0.460399</td>\n      <td>0.210884</td>\n      <td>0.575771</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>The author Tolkiens son has released a new fan...</td>\n      <td>marry fantasy blue Nietzsche awsome Tommy trol...</td>\n      <td>0.159256</td>\n      <td>0.372894</td>\n      <td>0.375381</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, sigmoid_kernel, rbf_kernel, polynomial_kernel, laplacian_kernel, cosine_similarity\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`', '[removed]', '>', '*', '_', \"&\", \"$\"]\n",
    "    stopwords = []\n",
    "    vocab = []\n",
    "    def __init__(self, stopwords=[], vocabulary=[]):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.stopwords = stopwords\n",
    "        self.vocab = vocabulary\n",
    "    def __call__(self, document):\n",
    "        from nltk import word_tokenize\n",
    "        sig_words = []\n",
    "        for word, tag in pos_tag(word_tokenize(document)):\n",
    "            lower_cased_tag = tag[0].lower()\n",
    "            wn_tag = lower_cased_tag if lower_cased_tag in ['a', 'r', 'n', 'v'] else None\n",
    "            if not wn_tag:\n",
    "                lemma = word\n",
    "            else:\n",
    "                lemma = self.wnl.lemmatize(word, wn_tag)\n",
    "            if lemma not in list(self.stopwords) + self.ignore_tokens: # and word in self.vocab:\n",
    "                sig_words.append(lemma.lower())\n",
    "        return sig_words\n",
    "\n",
    "swords = stopwords()\n",
    "bwords = badwords()\n",
    "smil = emoticons()\n",
    "#tokenizer = LemmaTokenizer(stopwords=swords)\n",
    "\n",
    "cva = CountVectorizer(lowercase=True, tokenizer=LemmaTokenizer())\n",
    "asdf = cva.fit_transform(df.get(\"body\"))\n",
    "all_vocabs = cva.get_feature_names()\n",
    "\n",
    "cvf = CountVectorizer(stop_words=list(swords)+list(bwords), lowercase=True, tokenizer=LemmaTokenizer(stopwords=list(swords)+list(bwords)))\n",
    "asdf = cvf.fit_transform(df.get(\"body\"))\n",
    "filtered_vocab = cvf.get_feature_names()\n",
    "\n",
    "# Significant words count\n",
    "cv = CountVectorizer(vocabulary=all_vocabs, stop_words=list(swords)+list(bwords), lowercase=True, tokenizer=LemmaTokenizer(stopwords=list(swords)+list(bwords)))\n",
    "wc_data = cv.fit_transform(df.get(\"body\"))\n",
    "wc_df = pd.DataFrame(wc_data.sum(axis=1))\n",
    "wc_df.columns = [\"wc\"]\n",
    "\n",
    "# Bad words count\n",
    "cv = CountVectorizer(vocabulary=bwords, stop_words=None, lowercase=True, tokenizer=tokenizer, ngram_range=(1,2)) # finds \"old bag\"\n",
    "bw_data = cv.fit_transform(df.get(\"body\"))\n",
    "bw_df = pd.DataFrame(bw_data.sum(axis=1))\n",
    "bw_df.columns = [\"bw\"]\n",
    "\n",
    "# Stop words count\n",
    "cv = CountVectorizer(vocabulary=swords, stop_words=None, lowercase=True, tokenizer=LemmaTokenizer())\n",
    "sw_data = cv.fit_transform(df.get(\"body\"))\n",
    "sw_df = pd.DataFrame(sw_data.sum(axis=1))\n",
    "sw_df.columns = [\"sw\"]\n",
    "\n",
    "# Positive smilies\n",
    "cv = CountVectorizer(vocabulary=smil[\"pos\"], analyzer=\"char\", ngram_range=(1,2), stop_words=None, lowercase=False) # char + 2 ngram = \":D\"\n",
    "smilp_data = cv.fit_transform(df.get(\"body\"))\n",
    "smilp_df = pd.DataFrame(smilp_data.sum(axis=1))\n",
    "smilp_df.columns = [\"smil+\"]\n",
    "\n",
    "# Negative smilies count\n",
    "cv = CountVectorizer(vocabulary=smil[\"neg\"], analyzer=\"char\", ngram_range=(1,2), stop_words=None, lowercase=False) # char + 2 ngram = \":D\"\n",
    "sniln_data = cv.fit_transform(df.get(\"body\"))\n",
    "smiln_df = pd.DataFrame(sniln_data.sum(axis=1))\n",
    "smiln_df.columns = [\"smil-\"]\n",
    "\n",
    "# Neutral smilies count\n",
    "cv = CountVectorizer(vocabulary=smil[\"neu\"], analyzer=\"char\", ngram_range=(1,2), stop_words=None, lowercase=False) # char + 2 ngram = \":D\"\n",
    "smile_data = cv.fit_transform(df.get(\"body\"))\n",
    "smile_df = pd.DataFrame(smile_data.sum(axis=1))\n",
    "smile_df.columns = [\"smil&\"]\n",
    "\n",
    "# TF-IDF cosine similarity toawrd topic\n",
    "submission_with_comments = [submission] + list(df.get(\"body\").array)\n",
    "tfidfv = TfidfVectorizer(vocabulary=filtered_vocab, lowercase=True, ngram_range=(1,1), smooth_idf=True, tokenizer=LemmaTokenizer(stopwords=list(swords)))\n",
    "tfidf_data = tfidfv.fit_transform(submission_with_comments)\n",
    "cosine_similarities = cosine_similarity(tfidf_data[0:1], tfidf_data[1:]).flatten()\n",
    "top_simi_df = pd.DataFrame(cosine_similarities)\n",
    "top_simi_df.columns = [\"top-cos-sim\"]\n",
    "\n",
    "# TF-IDF cosine similarity towards all documents\n",
    "# (possible to do just as toward topic by changing first element from submission to \" \".join(all_vocabs))\n",
    "submission_with_comments = [\" \".join(all_vocabs)] + list(df.get(\"body\").array)\n",
    "tfidfv = TfidfVectorizer(vocabulary=filtered_vocab, lowercase=True, ngram_range=(1,1), smooth_idf=True, tokenizer=LemmaTokenizer(stopwords=list(swords)))\n",
    "tfidf_data = tfidfv.fit_transform(submission_with_comments)\n",
    "cosine_similarities = cosine_similarity(tfidf_data[0:1], tfidf_data[1:]).flatten()\n",
    "all_simi_df = pd.DataFrame(cosine_similarities)\n",
    "all_simi_df.columns = [\"cos-sim\"]\n",
    "\n",
    "#tfidfv = TfidfVectorizer(vocabulary=all_vocabs, lowercase=True, ngram_range=(1,1), smooth_idf=True)\n",
    "#tfidf_data = tfidfv.fit_transform(df.get(\"body\"))\n",
    "#cosine_similarities = cosine_similarity(tfidf_data, tfidf_data)\n",
    "#cosine_similarities[cosine_similarities == 0] = np.nan\n",
    "#cosine_similarities = np.nanmean(cosine_similarities, axis=1)\n",
    "#all_simi_df = pd.DataFrame(cosine_similarities)\n",
    "#all_simi_df.columns = [\"cos-sim\"]\n",
    "\n",
    "# TF-IDF mean value (checks across all documents)\n",
    "tfidfv = TfidfVectorizer(vocabulary=all_vocabs, lowercase=True, ngram_range=(1,1), smooth_idf=True, tokenizer=LemmaTokenizer(stopwords=list(swords)))\n",
    "tfidf_data = tfidfv.fit_transform(df.get(\"body\")).todense()\n",
    "means = [0]*tfidf_data.shape[0]\n",
    "#means = np.nanmean(tfidf_data, axis=1)\n",
    "for i in range(0, tfidf_data.shape[0]):\n",
    "    word_count = wc_df.get(\"wc\")[i] + bw_df.get(\"bw\")[i] + sw_df.get(\"sw\")[i]\n",
    "    means[i] = tfidf_data[i].sum()/word_count\n",
    "    #tfidf_data[i][tfidf_data[i] == 0] = np.nan\n",
    "tfidf_df = pd.DataFrame(means)\n",
    "tfidf_df.columns = [\"tfidf-mean\"]\n",
    "#print(\n",
    "#    means[7], \n",
    "#    wc_df.get(\"wc\")[7],\n",
    "#    dict(zip(tfidfv.get_feature_names(), tfidf_data[7].tolist()[0]))\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "cv_dataframe = pd.concat([df, top_simi_df, all_simi_df, tfidf_df, wc_df, sw_df, bw_df, smilp_df, smiln_df, smile_df], axis=1)\n",
    "cv_dataframe"
   ]
  }
 ]
}