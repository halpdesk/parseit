{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('python_modules')",
   "metadata": {
    "interpreter": {
     "hash": "9634d4b890a726f71d8044046bc71cdc391c406dc663847f104c7db04bcb4cdc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "import math\n",
    "\n",
    "# Load pickle\n",
    "from parseit.data import load_pickle\n",
    "pickle_with_other_features = load_pickle(f\"data-16k-dec-3-other-features.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy (SFK): 14.56% (0.36%)\n",
      "\n",
      "Accuracy: 15.24% (1991 comments of 13066) for k=50\n",
      "\n",
      "[   1    2 1257 ...    1    1    1]\n",
      "Linear SVC Accuracy: 16.07% (2100 comments of 13066)\n",
      "Accuracy: 6.30% (823 comments of 13066) for k=1\n",
      "Accuracy: 12.44% (1626 comments of 13066) for k=6\n",
      "Accuracy: 13.95% (1823 comments of 13066) for k=11\n",
      "Accuracy: 14.31% (1870 comments of 13066) for k=16\n",
      "Accuracy: 15.01% (1961 comments of 13066) for k=21\n",
      "Accuracy: 15.00% (1960 comments of 13066) for k=26\n",
      "Accuracy: 15.13% (1977 comments of 13066) for k=31\n",
      "Accuracy: 14.97% (1956 comments of 13066) for k=36\n",
      "Accuracy: 14.85% (1940 comments of 13066) for k=41\n",
      "Accuracy: 15.08% (1970 comments of 13066) for k=46\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "label\n 1       6451\n 2       6362\n 3       3959\n 4       1672\n 5       1615\n         ... \n 7375       1\n 7379       1\n 7381       1\n 7396       1\n-92         1\nLength: 4838, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "df = pickle_with_other_features.copy()\n",
    "\n",
    "# Define parameters\n",
    "k = 50\n",
    "bins = 10\n",
    "test_size = 0.3\n",
    "X = df[[\"top-cos-sim\", \"cos-sim\", \"tfidf-mean\", \"wc\", \"sw\", \"bw\", \"smil+\", \"smil-\", \"smil&\", \"nam\", \"lnk\"]]\n",
    "#X = dfwf[[\"top-cos-sim\", \"wc\", \"bw\", \"smil+\"]]\n",
    "y = df[[\"label\"]]\n",
    "\n",
    "\n",
    "# Bin all of y first\n",
    "# uniform = All bins in each feature have identical widths.\n",
    "# quantile = All bins in each feature have the same number of points.\n",
    "# kmeans = Values in each bin have the same nearest center of a 1D k-means cluster.\n",
    "#est = KBinsDiscretizer(n_bins=bins, encode=\"ordinal\", strategy=\"uniform\") #\n",
    "#est.fit(y)\n",
    "#y = pd.DataFrame(data=est.transform(y), index=y.index)\n",
    "\n",
    "#drop = y[y == 0][100:]\n",
    "#y = y.drop(index=drop.index)\n",
    "#X = X.drop(index=drop.index)\n",
    "#display(y)\n",
    "\n",
    "X_unscaled_train, X_unscaled_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# All variables must be in the same scale: normalization or min-max-scaler\n",
    "# How to scale so that each distance is meaningful: https://medium.com/analytics-vidhya/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "scaler.fit(X_unscaled_train)\n",
    "X_train = scaler.transform(X_unscaled_train)\n",
    "\n",
    "\n",
    "# Try with SKF\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "n_scores = cross_val_score(knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score=\"raise\")\n",
    "# report model performance\n",
    "print(\"Accuracy (SFK): %.2f%% (%.2f%%)\\n\" % (mean(n_scores)*100, std(n_scores)*100))\n",
    "\n",
    "\n",
    "# Try without SKF\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "y_pred = clf.predict(scaler.transform(X_unscaled_valid))\n",
    "#print(y_pred)\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred, normalize=False)\n",
    "accuracy_norm = metrics.accuracy_score(y_valid, y_pred, normalize=True)\n",
    "print(f'Accuracy: {\"%.2f\" % (accuracy_norm * 100)}% ({accuracy} comments of {math.floor(len(y.index)*test_size)}) for k={k}\\n')\n",
    "\n",
    "# Try with LinearSVC\n",
    "svc = LinearSVC(random_state=0, tol=1e-05)\n",
    "clf = svc.fit(X_train, y_train)\n",
    "# Scale X_valid after fitting the model: https://datascience.stackexchange.com/questions/38395/standardscaler-before-and-after-splitting-data\n",
    "y_pred = clf.predict(scaler.transform(X_unscaled_valid))\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred, normalize=False)\n",
    "accuracy_norm = metrics.accuracy_score(y_valid, y_pred, normalize=True)\n",
    "print(f'Linear SVC Accuracy: {\"%.2f\" % (accuracy_norm * 100)}% ({accuracy} comments of {math.floor(len(y.index)*test_size)})')\n",
    "\n",
    "# Try different ranges for k\n",
    "k_range = range(1, k, math.floor(k/10))\n",
    "for kk in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=kk)\n",
    "    clf = knn.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(scaler.transform(X_unscaled_valid))\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_pred, normalize=False)\n",
    "    accuracy_norm = metrics.accuracy_score(y_valid, y_pred, normalize=True)\n",
    "    print(f'Accuracy: {\"%.2f\" % (accuracy_norm * 100)}% ({accuracy} comments of {math.floor(len(y.index)*test_size)}) for k={kk}')\n",
    "    \n",
    "\n",
    "\n",
    "display(y.value_counts())"
   ]
  }
 ]
}